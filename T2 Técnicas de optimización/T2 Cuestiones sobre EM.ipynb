{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2023_01_30_Cuestión 3.** $\\;$ Las siguientes afirmaciones se refieren a la estimación por máxima verosimilitud de los parámetros de una mezcla de $K$ gaussianas (vector-media y peso de cada gaussiana) mediante un conjunto de vectores de entrenamiento cualquiera de dimensión $D$. Identifica cuál es **falsa**.\n",
    "1. Los parámetros de la mezcla se estiman adecuadamente mediante un algoritmo de **esperanza maximización** (EM)\n",
    "2. La verosimilitud del conjunto de entrenamiento, calculada con los parámetros estimados, aumenta en cada iteración del EM\n",
    "3. El algoritmo EM obtiene los valores óptimos de los parámetros a estimar\n",
    "4. En cada iteración, el algoritmo EM estima los valores de las variables ocultas que, en este caso, son los pesos de las gaussianas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución:** $\\;$ La 3 es falsa ya que el EM encuentra un óptimo local, no necesariamente global."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2022_01_24_Cuestión 3.** $\\;$ En el problema de aprendizaje de modelos probabilísticos con variables observables $\\boldsymbol{x}_n$ y latentes $\\boldsymbol{z}_n$, la log-verosimilitud se expresa como:\n",
    "$$L_S(\\mathbf{\\Theta}) ~=~\\sum_{n=1}^N\\log \\left(\\sum_{\\boldsymbol{z}_n} P(\\boldsymbol{x}_n,\\boldsymbol{z}_n\\mid\\mathbf{\\Theta}) \\right)$$\n",
    "y se utiliza la técnica esperanza-maximización (EM).  Indicar cuál de las siguientes afirmaciones es cierta:\n",
    "1. En cada iteración, el paso E consiste en obtener una estimación de todas las variables $\\boldsymbol{x}_n$ y $\\boldsymbol{z}_n$, y el paso M,obtener los parámetros óptimos de $\\mathbf{\\Theta}$ utilizando la estimación de las variables $\\boldsymbol{x}_n$ y $\\boldsymbol{z}_n$ obtenidas en el paso E.\n",
    "2. En cada iteración, el paso E consiste en obtener una estimación de los valores de las variables latentes $\\boldsymbol{z}_n$, y el paso M, obtener los parámetros óptimos de $\\mathbf{\\Theta}$ utilizando los estimadores de $\\boldsymbol{z}_n$ obtenidas en el paso E.\n",
    "3. En cada iteración, el paso E consiste en obtener los valores de las variables latentes $\\boldsymbol{z}_n$ que maximizan la función objetivo $L_S(\\mathbf{\\Theta})$, y el paso M, obtener los parámetros óptimos de $\\mathbf{\\Theta}$ utilizando la estimación de las variables $\\boldsymbol{z}_n$ obtenidas en el paso E.\n",
    "4. En cada iteración, el paso E consiste en obtener los valores de todas las variables $\\boldsymbol{x}_n$ y $\\boldsymbol{z}_n$ que maximizan la función $L_S(\\mathbf{\\Theta})$, y el paso M, obtener los parámetros óptimos de $\\mathbf{\\Theta}$ utilizando la estimación de las variables $\\boldsymbol{x}_n$ y $\\boldsymbol{z}_n$ obtenidas en el paso E."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución:** $\\;$ La 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2022_01_10_Cuestión 4.** $\\;$ En el aprendizaje de modelos probabilísticos mediante el algoritmo esperanza-maximización indicar qué afirmación es correcta.\n",
    "1. Es el método adecuado cuando las muestras de entrenamiento están completas.\n",
    "2. A partir de una cierta estimación de las variables ocultas se busca el óptimo de una función auxiliar como solución final del problema original.\n",
    "3. Es el método adecuado cuando no hay variables ocultas.\n",
    "4. En cada iteración, a partir de una cierta estimación de las variables ocultas se busca el óptimo de una función auxiliar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución:** $\\;$ La 4."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
