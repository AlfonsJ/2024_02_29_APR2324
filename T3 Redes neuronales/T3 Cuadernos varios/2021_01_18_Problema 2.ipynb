{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2021_01_18_Problema 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div><table border-collapse: collapse><tr>\n",
    "<td style=\"border: none; text-align:left; vertical-align:top; padding:0; margin:0;\" width=550>\n",
    "\n",
    "El perceptrón multicapa de la figura se utiliza para resolver un problema de regresión, con función de activación del nodo de la capa de salida de tipo lineal y de los nodos de la capa oculta de tipo **sigmoide,** y factor de aprendizaje $\\rho=1.0$.\n",
    "\n",
    "Dado un par de entrenamiento $(\\boldsymbol{x}^t,t)~=((2,2),-1)$, calcula:\n",
    "1. Las salidas de todos los nodos.\n",
    "2. Los correspondientes errores en el nodo de la capa de salida y en los nodos de la capa oculta.\n",
    "3. Los nuevos valores de los pesos de las conexiones $\\theta^2_{12}$ y $\\theta^1_{21}$.\n",
    "\n",
    "</td><td style=\"border: none; padding:0; margin:0;\" width=50><br></td>\n",
    "<td style=\"border: none; text-align:right; vertical-align:top; padding:0; margin:0;\" width=450>\n",
    "\n",
    "<img src=\"2021_01_18_Problema 2.png\" width=400>\n",
    "\n",
    "</td></tr></table></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solución\n",
    "$$\\begin{align*}\n",
    "\\phi^1_1&=\\theta^1_{10}+\\theta^1_{11}x_1+\\theta^1_{12}x_2=-3%\n",
    "&&\\text{pre-activación del nodo 1 de la capa oculta}\\\\\n",
    "s^1_1&=\\sigma(\\phi^1_1)=0.047426%\n",
    "&&\\text{activación del nodo 1 de la capa oculta}\\\\%\n",
    "\\phi^1_2&=\\theta^1_{20}+\\theta^1_{21}x_1+\\theta^1_{22}x_2=-1%\n",
    "&&\\text{pre-activación del nodo 2 de la capa oculta}\\\\%\n",
    "s^1_2&=\\sigma(\\phi^1_1)=0.268941%\n",
    "&&\\text{activación del nodo 2 de la capa oculta}\\\\%\n",
    "\\phi^2_1&=\\theta^2_{10}+\\theta^2_{11}s^1_1+\\theta^2_{12}s^1_2=0.77848%\n",
    "&&\\text{pre-activación del nodo 1 de la capa de salida}\\\\%\n",
    "s^2_1&=\\phi^2_1=0.77848%\n",
    "&&\\text{activación del nodo 1 de la capa de salida}\\\\%\n",
    "\\delta^2_1&=(t_1-s^2_1)=1.7785%\n",
    "&&\\text{error en el nodo 1 de la capa de salida}\\\\%\n",
    "\\delta^1_1&=(\\delta^2_1\\theta^2_{11})\\sigma'(\\phi^1_1)\\\\%\n",
    "&=(\\delta^2_1\\theta^2_{11})s^1_1(1-s^1_1)=-0.08035\n",
    "&&\\text{error en el nodo 1 de la capa oculta}\\\\%\n",
    "\\delta^1_2&=(\\delta^2_1\\theta^2_{12})\\sigma'(\\phi^1_2)\\\\\n",
    "&=(\\delta^2_1\\theta^2_{12})s^1_2(1-s^1_2)=0.34967%\n",
    "&&\\text{error en el nodo 2 de la capa oculta}\\\\%\n",
    "\\theta^2_{12}&=\\theta^2_{12}+\\Delta\\theta^2_{12}\\\\\n",
    "&=\\theta^2_{12}+\\rho\\delta^2_1s^1_2\\\\\n",
    "&=-1+1\\cdot -1.7785\\cdot 0.268941\\\\%\n",
    "&=-1.47831%\n",
    "&&\\text{nuevo peso de la conexión $\\theta^2_{12}$}\\\\%\n",
    "\\theta^1_{21}&=\\theta^1_{21}+\\Delta\\theta^1_{21}\\\\\n",
    "&=\\theta^1_{21}+\\rho\\delta^1_2x_1\\\\\n",
    "&=1+1\\cdot 0.34967\\cdot 2=1.69934%\n",
    "&&\\text{nuevo peso de la conexión $\\theta^1_{21}$}%\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solución con notación matricial\n",
    "\n",
    "**Capa oculta:** $\\qquad\\boldsymbol{h}=\\boldsymbol{\\sigma}(\\boldsymbol{z})\\qquad$ con $\\qquad\\boldsymbol{z}=\\mathbf{W}\\boldsymbol{x}+\\boldsymbol{b}_1\\qquad\\mathbf{W}=\\begin{pmatrix}-1&-1\\\\1&-1\\end{pmatrix}\\qquad\\boldsymbol{b}_1=\\begin{pmatrix}1\\\\-1\\end{pmatrix}$\n",
    "\n",
    "**Capa de salida:** $\\qquad\\hat{y}=\\mathbf{V}\\boldsymbol{h}+b_2\\qquad$ con $\\qquad\\mathbf{V}=\\begin{pmatrix}1&-1\\end{pmatrix}\\qquad b_2=1$\n",
    "\n",
    "**Pérdida cuadrática (para un par entrada-salida):** $\\qquad\\mathcal{L}=\\frac{1}{2}(y-\\hat{y})^2$\n",
    "\n",
    "**Par entrada-salida:** $\\qquad\\boldsymbol{x}=(2,2)^t\\qquad y=-1$\n",
    "\n",
    "**Forward:** $\\;$ pre-activaciones, activaciones y pérdida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z = [-3 -1]\n",
      "h = [0.0474 0.2689]\n",
      "haty = 0.7785\n",
      "loss = 1.5815\n"
     ]
    }
   ],
   "source": [
    "import numpy as np; np.set_printoptions(precision=4)\n",
    "sigmoid = lambda x: 1.0 / (1.0 + np.exp(-x));\n",
    "x = np.array([2, 2]); y = -1\n",
    "W = np.array([[-1, -1], [1, -1]]); b1 = np.array([1, -1])\n",
    "V = np.array([1, -1]); b2 = 1\n",
    "z = (W @ x + b1);                    print(\"z =\", z)\n",
    "h = sigmoid(z);                      print(\"h =\", h)\n",
    "haty = V @ h + b2;                   print(\"haty =\", round(haty, 4))\n",
    "loss = .5 * np.square(y-haty).sum(); print(\"loss =\", round(loss, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Backward:** $\\;$ Jacobianas de la pérdida con respecto a $\\ldots$\n",
    "$$\\begin{align*}\n",
    "u=&\\dfrac{\\partial\\mathcal{L}}{\\partial\\hat{y}}=\\hat{y}-y\n",
    "&&\\text{la predicción (activación de la capa de salida)}\\\\\n",
    "\\boldsymbol{g}_{\\mathbf{V}}=u&\\dfrac{\\partial\\hat{y}}{\\partial\\mathbf{V}}=\\boldsymbol{h}u\n",
    "&&\\text{la transformación lineal de la capa de salida}\\\\\n",
    "g_{\\boldsymbol{b}_2}=u&\\dfrac{\\partial\\hat{y}}{\\partial b_2}=u\n",
    "&&\\text{el sesgo de la capa de salida}\\\\\n",
    "\\boldsymbol{u}^t=u&\\dfrac{\\partial\\hat{y}}{\\partial\\boldsymbol{h}}=u\\mathbf{V}\n",
    "&&\\text{la activación de la capa oculta}\\\\\n",
    "\\boldsymbol{u}^t=\\boldsymbol{u}^t&\\dfrac{\\partial\\boldsymbol{h}}{\\partial\\boldsymbol{z}}=\\boldsymbol{u}^t\\operatorname{diag}(\\boldsymbol{\\sigma}'(\\boldsymbol{z}))\n",
    "&&\\text{la pre-activación de la capa oculta}\\\\\n",
    "\\boldsymbol{g}_{\\mathbf{W}}=\\boldsymbol{u}^t&\\dfrac{\\partial\\boldsymbol{z}}{\\partial\\mathbf{W}}=\\boldsymbol{x}\\boldsymbol{u}^t\n",
    "&&\\text{la transformación lineal de la capa oculta}\\\\\n",
    "\\boldsymbol{g}_{\\boldsymbol{b}_1}=\\boldsymbol{u}^t&\\dfrac{\\partial\\boldsymbol{z}}{\\partial\\boldsymbol{b}_1}=\\boldsymbol{u}^t\n",
    "&&\\text{el sesgo de la capa oculta}\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J_haty = 1.7785\n",
      "J_V = [[0.0843]\n",
      " [0.4783]]\n",
      "J_b2 = 1.7785\n",
      "J_h = [ 1.7785 -1.7785]\n",
      "J_z = [ 0.0803 -0.3497]\n",
      "J_W = [[ 0.1607 -0.6993]\n",
      " [ 0.1607 -0.6993]]\n",
      "J_b1 = [ 0.0803 -0.3497]\n"
     ]
    }
   ],
   "source": [
    "J_haty = haty-y;                         print(\"J_haty =\", round(J_haty, 4))\n",
    "J_V = np.outer(h, J_haty);               print(\"J_V =\", J_V)\n",
    "J_b2 = J_haty;                           print(\"J_b2 =\", round(J_b2, 4))\n",
    "J_h = J_haty * V;                        print(\"J_h =\", J_h)\n",
    "J_z = J_h * sigmoid(z) * sigmoid(-z);    print(\"J_z =\", J_z)\n",
    "J_W = np.outer(x, J_z);                  print(\"J_W =\", J_W)\n",
    "J_b1 = J_z;                              print(\"J_b1 =\", J_b1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Actualización de parámetros:** $\\quad\\mathbf{V}=\\mathbf{V}-\\rho\\boldsymbol{g}_{\\mathbf{V}}^t\\qquad b_2=b_2-\\eta g_{b_2}\\qquad\\mathbf{W}=\\mathbf{W}-\\eta\\boldsymbol{g}_{\\mathbf{W}}^t\\qquad\\boldsymbol{b}_1=\\boldsymbol{b}_1-\\eta\\boldsymbol{g}_{\\boldsymbol{b}_1}^t$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V = [[ 0.9157 -1.4783]]\n",
      "b2 = -0.7784844518075715\n",
      "W = [[-1.1607 -1.1607]\n",
      " [ 1.6993 -0.3007]]\n",
      "b1 = [ 0.9197 -0.6503]\n"
     ]
    }
   ],
   "source": [
    "V  = V  - 1.0 * J_V.T; print(\"V =\", V)\n",
    "b2 = b2 - 1.0 * J_b2;  print(\"b2 =\", b2)\n",
    "W  = W  - 1.0 * J_W.T; print(\"W =\", W)\n",
    "b1 = b1 - 1.0 * J_b1;  print(\"b1 =\", b1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
