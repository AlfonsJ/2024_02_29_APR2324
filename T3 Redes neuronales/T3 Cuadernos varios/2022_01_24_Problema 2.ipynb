{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2022_01_24_Problema 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div><table border-collapse: collapse><tr>\n",
    "<td style=\"border: none; text-align:left; vertical-align:top; padding:0; margin:0;\" width=550>\n",
    "\n",
    "La red hacia adelante (\"feedforward\") de la figura se utiliza para resolver un problema de regresión, con función de activación de los nodos de la capa de oculta de tipo **sigmoid** y lineal en el nodo de la capa de salida, y factor de aprendizaje $\\rho=1.0$.\n",
    "\n",
    "Dados unos pesos iniciales $\\,\\theta_{1}=\\theta_{2}=\\theta_{3}=\\theta_{4}=\\theta_{5}=1.0,\\,$ un vector de entrada $\\boldsymbol{x}^t=(0,1)$ y su valor deseado de salida $t=1,\\,$ calcula:\n",
    "1. Las salidas de todas las unidades.\n",
    "2. Los correspondientes errores en el nodo de la capa de salida y en el de la capa oculta.\n",
    "3. Los nuevos valores de los pesos de las conexiones.\n",
    "\n",
    "*Pista:* La actualización de pesos en esta red sigue la misma formulación que en el BackProp para el perceptrón multicapa\n",
    "convencional: el incremento de peso es $\\Delta\\theta~=~\\rho~z~\\delta$, donde $\\rho$ es el factor de aprendizaje, $z$ es la entrada del arco asociado al peso $\\theta$, y $\\delta$ es el error que se observa en la salida de la unidad a la que llega ese arco, multiplicado por la derivada de la función de activación.\n",
    "\n",
    "</td><td style=\"border: none; padding:0; margin:0;\" width=50><br></td>\n",
    "<td style=\"border: none; text-align:right; vertical-align:top; padding:0; margin:0;\" width=450>\n",
    "\n",
    "<img src=\"2022_01_24_Problema 2.png\" width=400>\n",
    "\n",
    "</td></tr></table></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solución\n",
    "$$\\begin{align*}\n",
    "\\phi^1_1&=\\theta_{1}+\\theta_{2}x_2=1+1\\cdot 1=2\\\\%\n",
    "s^1_1&=\\sigma(\\phi^1_1)=0.880797\\\\%\n",
    "\\phi^2_1&=\\theta_{4}+\\theta_{3}x_1+\\theta_{5}s^1_1=1+1\\cdot 0+1\\cdot 0.880797=1.880797\\\\%\n",
    "s^2_1&=\\phi^2_1=1.880797\\\\%\n",
    "\\delta^2_1&=(t_1-s^2_1)=(1-1.880797)=-0.880797\\\\%\n",
    "\\delta^1_1&=(\\delta^2_1~\\theta_{5})s^1_1~(1-s^1_1)=-0.880797\\cdot 1\\cdot 0.880797\\cdot (1-0.880797)=-0.092478\\\\%\n",
    "\\theta_{1}&=\\theta_{1}+\\rho\\delta^1_1(+1)=1+1\\cdot-0.092478\\cdot 1=0.90752\\\\%\n",
    "\\theta_{2}&=\\theta_{2}+\\rho\\delta^1_1x_2=1+1\\cdot-0.092478\\cdot 1=0.90752\\\\%\n",
    "\\theta_{3}&=\\theta_{3}+\\rho\\delta^2_1x_1=1+1\\cdot-0.880797\\cdot 0=1\\\\%\n",
    "\\theta_{4}&=\\theta_{4}+\\rho\\delta^2_1(+1)=1+1\\cdot-0.880797\\cdot 1=0.119203\\\\%\n",
    "\\theta_{5}&=\\theta_{5}+\\rho\\delta^2_1s^1_1=1+1\\cdot-0.880797\\cdot 0.880797=0.224196%\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solución con notación matricial\n",
    "\n",
    "**Capa oculta:** $\\qquad s_1^1=\\sigma(\\phi_1^1)\\qquad$ con $\\qquad\\phi_1^1=\\theta_1+\\theta_2x_2\\qquad\\theta_1=\\theta_2=1$\n",
    "\n",
    "**Capa de salida:** $\\qquad s_1^2=\\phi_1^2\\qquad$ con $\\qquad\\phi_1^2=\\theta_4+\\theta_3x_1+\\theta_5s_1^1\\qquad\\theta_3=\\theta_4=\\theta_5=1$\n",
    "\n",
    "**Pérdida cuadrática:** $\\quad\\mathcal{L}=\\frac{1}{2}(y-s_1^2)^2\\qquad$ para $\\qquad\\boldsymbol{x}=(0,1)^t\\qquad y=1$\n",
    "\n",
    "**Forward:** $\\;$ pre-activaciones, activaciones y pérdida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phi11 = 2.0\n",
      "s11 = 0.8808\n",
      "phi12 = 1.8808\n",
      "s12 =  1.8808\n",
      "loss = 0.3879\n"
     ]
    }
   ],
   "source": [
    "import numpy as np; np.set_printoptions(precision=4)\n",
    "sigmoid = lambda x: 1.0 / (1.0 + np.exp(-x));\n",
    "x = np.array([0, 1]); y = 1.\n",
    "t1 = t2 = t3 = t4 = t5 = 1.\n",
    "phi11 = t1 + t2 * x[1];            print(\"phi11 =\", round(phi11, 4))\n",
    "s11 = sigmoid(phi11);              print(\"s11 =\", round(s11, 4))\n",
    "phi12 = t4 + t3 * x[0] + t5 * s11; print(\"phi12 =\", round(phi12, 4))\n",
    "s12 = phi12;                       print(\"s12 = \", round(s12, 4))\n",
    "loss = .5 *  np.square(y - s12);   print(\"loss =\", round(loss, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Backward:** $\\;$ Jacobianas de la pérdida con respecto a $\\ldots$\n",
    "$$\\begin{align*}\n",
    "u=&\\dfrac{d\\mathcal{L}}{ds_1^2}=s_1^2-y%\n",
    "&&\\text{la predicción (activación de la capa de salida)}\\\\\\\n",
    "u=u&\\dfrac{ds_1^2}{d\\phi_1^2}=u%\n",
    "&&\\text{la pre-activación de la capa de salida}\\\\\n",
    "g_{\\theta_4}=u&\\dfrac{d\\phi_1^2}{d\\theta_4}=u%\n",
    "&&\\theta_4\\\\\n",
    "g_{\\theta_3}=u&\\dfrac{d\\phi_1^2}{d\\theta_3}=ux_1%\n",
    "&&\\theta_3\\\\\n",
    "g_{\\theta_5}=u&\\dfrac{d\\phi_1^2}{d\\theta_5}=us_1^1%\n",
    "&&\\theta_5\\\\\n",
    "u=u&\\dfrac{d\\phi_1^2}{ds_1^1}=u\\theta_5%\n",
    "&&\\text{la activación de la capa oculta}\\\\\n",
    "u=u&\\dfrac{ds_1^1}{d\\phi_1^1}=u\\sigma'(\\phi_1^1)%\n",
    "&&\\text{la pre-activación de la capa oculta}\\\\\n",
    "g_{\\theta_1}=u&\\dfrac{d\\phi_1^1}{d\\theta_1}=u%\n",
    "&&\\theta_1\\\\\n",
    "g_{\\theta_2}=u&\\dfrac{d\\phi_1^1}{d\\theta_2}=ux_2%\n",
    "&&\\theta_2\n",
    "\\end{align*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J_s12 = 0.8808\n",
      "J_phi12 = 0.8808\n",
      "J_t4 =  0.8808\n",
      "J_t3 = 0.0\n",
      "J_t5 = 0.7758\n",
      "J_s11 = 0.8808\n",
      "J_phi11 =  0.0925\n",
      "J_t1 = 0.0925\n",
      "J_t2 = 0.0925\n"
     ]
    }
   ],
   "source": [
    "J_s12 = s12 - y;                                    print(\"J_s12 =\", round(J_s12, 4))\n",
    "J_phi12 = J_s12;                                    print(\"J_phi12 =\", round(J_phi12, 4))\n",
    "J_t4 = J_phi12;                                     print(\"J_t4 = \", round(J_t4, 4))\n",
    "J_t3 = J_phi12 * x[0];                              print(\"J_t3 =\", round(J_t3, 4))\n",
    "J_t5 = J_phi12 * s11;                               print(\"J_t5 =\", round(J_t5, 4))\n",
    "J_s11 = J_phi12 * t5;                               print(\"J_s11 =\", round(J_s11, 4))\n",
    "J_phi11 = J_s11 * sigmoid(phi11) * sigmoid(-phi11); print(\"J_phi11 = \", round(J_phi11, 4))\n",
    "J_t1 = J_phi11;                                     print(\"J_t1 =\", round(J_t1, 4))\n",
    "J_t2 = J_phi11 * x[1];                              print(\"J_t2 =\", round(J_t2, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Actualización de parámetros:** $\\quad\\boldsymbol{\\theta}=\\boldsymbol{\\theta}-\\rho\\boldsymbol{g}_{\\boldsymbol{\\theta}}^t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1 = 0.9075\n",
      "t2 = 0.9075\n",
      "t3 = 1.0\n",
      "t4 = 0.1192\n",
      "t5 = 0.2242\n"
     ]
    }
   ],
   "source": [
    "t1 -= J_t1; print(\"t1 =\", round(t1, 4))\n",
    "t2 -= J_t2; print(\"t2 =\", round(t2, 4))\n",
    "t3 -= J_t3; print(\"t3 =\", round(t3, 4))\n",
    "t4 -= J_t4; print(\"t4 =\", round(t4, 4))\n",
    "t5 -= J_t5; print(\"t5 =\", round(t5, 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
